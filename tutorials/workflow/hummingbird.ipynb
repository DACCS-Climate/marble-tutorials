{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hummingbird"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from owslib.wps import WebProcessingService\n",
    "import requests\n",
    "from lxml import etree\n",
    "import owslib\n",
    "owslib.__version__\n",
    "\n",
    "verify_ssl = True if 'DISABLE_VERIFY_SSL' not in os.environ else False\n",
    "\n",
    "def parseStatus(execute):\n",
    "    o = requests.get(execute.statusLocation, verify=verify_ssl)\n",
    "    t = etree.fromstring(o.content)\n",
    "    ref = t.getchildren()[-1].getchildren()[-1].getchildren()[-1].get('{http://www.w3.org/1999/xlink}href')\n",
    "\n",
    "    return ref"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hummingbird 0.5_dev\n"
     ]
    }
   ],
   "source": [
    "wps_url = 'https://pavics.ouranos.ca/twitcher/ows/proxy/hummingbird/wps'\n",
    "# connection\n",
    "wps = WebProcessingService(url=wps_url, verify=verify_ssl)\n",
    "# print wps title\n",
    "print(wps.identification.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncdump \t : Run ncdump to retrieve NetCDF header metadata. \n",
      "\n",
      "spotchecker \t : Checks a single uploaded or remote dataset against a variety of compliance standards. The dataset is either in the NetCDF format or a remote OpenDAP resource. Available compliance standards are the Climate and Forecast conventions (CF) and project specific rules for CMIP6 and CORDEX. \n",
      "\n",
      "cchecker \t : Runs the IOOS Compliance Checker tool to check datasets against compliance standards. Each compliance standard is executed by a Check Suite, which functions similar to a Python standard Unit Test. A Check Suite runs one or more checks against a dataset, returning a list of Results which are then aggregated into a summary. Development and maintenance for the compliance checker is done by the Integrated Ocean Observing System (IOOS). \n",
      "\n",
      "cfchecker \t : The NetCDF Climate Forcast Conventions compliance checker by CEDA. This process allows you to run the compliance checker to check that the contents of a NetCDF file comply with the Climate and Forecasts (CF) Metadata Convention. The CF-checker was developed at the Hadley Centre for Climate Prediction and Research, UK Met Office by Rosalyn Hatcher. This work was supported by PRISM (PRogramme for Integrated Earth System Modelling). Development and maintenance for the CF-checker has now been taken over by the NCAS Computational Modelling Services (NCAS-CMS). If you have suggestions for improvement then please contact Rosalyn Hatcher at NCAS-CMS (r.s.hatcher@reading.ac.uk). \n",
      "\n",
      "cmor_checker \t : Calls the CMIP6 cmor checker to verify CMIP6 compliance.CMIP6 CMOR checker will verify that all attributes in the input file are present and conform to CMIP6 for publication into ESGF. \n",
      "\n",
      "qa_cfchecker \t : The NetCDF Climate Forcast Conventions compliance checker by DKRZ. This process allows you to run the compliance checker to check that the contents of a NetCDF file comply with the Climate and Forecasts (CF) Metadata Convention. The CF Conformance checker applies to conventions 1.4 -1.7draft. Development and maintenance for the CF-checker is done by the German Climate Computing Centre (DKRZ). If you have suggestions for improvement then please contact Heinz-Dieter Hollweg at DKRZ (hollweg@dkrz.de). \n",
      "\n",
      "qa_checker \t : The Quality Assurance checker QA-DKRZ checks conformance of meta-data of climate simulations given in NetCDF format with conventions and rules of climate model projects. At present, checking of CF Conventions, CMIP5, and CORDEX is supported. Development and maintenance for the QA checker is done by the German Climate Computing Centre (DKRZ). If you have suggestions for improvement then please contact Heinz-Dieter Hollweg at DKRZ (hollweg@dkrz.de). \n",
      "\n",
      "cdo_sinfo \t : Runs CDO to retrieve NetCDF metadata information. Calls the sinfo operator of CDO (Climate Data Operator) on a NetCDF file and returns a document with metadata information. \n",
      "\n",
      "cdo_operation \t : Calls CDO operations like monmax on a NetCDF file. \n",
      "\n",
      "cdo_copy \t : Calls CDO to copy or concatenate datasets. All input datasets need to have the same structure with the same variables on different timesteps. \n",
      "\n",
      "cdo_bbox \t : Runs CDO to clip a bounding-box from a NetCDF file. Calls the CDO (Climate Data Operators) sellonlatbox operator with a bounding-box and returns the resulting NetCDF file. \n",
      "\n",
      "cdo_indices \t : Calculates climate indices like summer days using CDO. Calls the Climate Data Operators (CDO) tool with a single dataset (NetCDF, OpenDAP) provided and uses the chosen operator to calculate climate indices written to a NetCDF file. \n",
      "\n",
      "ensembles \t : Calling cdo to calculate ensembles operations. \n",
      "\n",
      "cdo_inter_mpi \t : CDO Remapping of NetCDF File(s) with multiprocessing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for process in wps.processes:\n",
    "    print ('%s \\t : %s \\n' %(process.identifier, process.abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ncdump to retrieve NetCDF header metadata.\n",
      "Inputs:\n",
      " *  dataset\n",
      " *  dataset_opendap\n"
     ]
    }
   ],
   "source": [
    "proc_name = 'ncdump'\n",
    "process = wps.describeprocess(proc_name) # get process info\n",
    "print(process.abstract)\n",
    "print(\"Inputs:\")\n",
    "for inputs in process.dataInputs:\n",
    "    print(' * ', inputs.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc\n"
     ]
    }
   ],
   "source": [
    "nc_url = 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc'\n",
    "print(nc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dataset_opendap', 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc')]\n"
     ]
    }
   ],
   "source": [
    "myinputs = []\n",
    "myinputs.append(('dataset_opendap',nc_url)) # inputs : use opendap link of a single netcdf file from catalogue search to erun ncdump\n",
    "print(myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncdump\n"
     ]
    }
   ],
   "source": [
    "print(proc_name)\n",
    "execute = wps.execute(proc_name, myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wps:ExecuteResponse xmlns:gml=\"http://www.opengis.net/gml\" xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:wps=\"http://www.opengis.net/wps/1.0.0\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/wps/1.0.0 http://schemas.opengis.net/wps/1.0.0/wpsExecute_response.xsd\" service=\"WPS\" version=\"1.0.0\" xml:lang=\"en-US\" serviceInstance=\"https://pavics.ouranos.ca:443/wps?service=WPS&amp;request=GetCapabilities\" statusLocation=\"https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/1df79124-3173-11e9-b38b-0242ac19000f.xml\">\n",
      "  <wps:Process wps:processVersion=\"4.4.1.1\">\n",
      "    <ows:Identifier>ncdump</ows:Identifier>\n",
      "    <ows:Title>NCDump</ows:Title>\n",
      "    <ows:Abstract>Run ncdump to retrieve NetCDF header metadata.</ows:Abstract>\n",
      "  </wps:Process>\n",
      "  <wps:Status creationTime=\"2019-02-15T22:43:31Z\">\n",
      "    <wps:ProcessSucceeded>PyWPS Process NCDump finished</wps:ProcessSucceeded>\n",
      "  </wps:Status>\n",
      "  <wps:ProcessOutputs>\n",
      "    <wps:Output>\n",
      "      <ows:Identifier>output</ows:Identifier>\n",
      "      <ows:Title>NetCDF Metadata</ows:Title>\n",
      "      <ows:Abstract>NetCDF Metadata</ows:Abstract>\n",
      "      <wps:Reference xlink:href=\"https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/1df79124-3173-11e9-b38b-0242ac19000f/nc_dump_zKu8Os.txt\" mimeType=\"text/plain\"/>\n",
      "    </wps:Output>\n",
      "  </wps:ProcessOutputs>\n",
      "</wps:ExecuteResponse>\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "print(etree.tostring(execute.response).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  ProcessSucceeded\n",
      "https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/1df79124-3173-11e9-b38b-0242ac19000f.xml\n"
     ]
    }
   ],
   "source": [
    "execute.checkStatus()\n",
    "print(\"Status: \", execute.status)\n",
    "print(execute.statusLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output reference :\n",
      "* https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/c53de772-33ca-11e9-9a7a-0242ac19000f/nc_dump_RNoL6I.txt\n",
      "\n",
      "NCDUMP results :\n",
      " netcdf nrcan_canada_daily_tasmin_2013.nc {\n",
      "dimensions:\n",
      "\ttime = UNLIMITED ; // (365 currently)\n",
      "\tlat = 510 ;\n",
      "\tlon = 1068 ;\n",
      "\tts = 3 ;\n",
      "variables:\n",
      "\tfloat lon(lon) ;\n",
      "\t\tlon:units = \"degrees_east\" ;\n",
      "\t\tlon:long_name = \"longitude\" ;\n",
      "\t\tlon:standard_name = \"longitude\" ;\n",
      "\t\tlon:axis = \"X\" ;\n",
      "\t\tlon:_ChunkSizes = 1068 ;\n",
      "\tfloat lat(lat) ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:units = \"degrees_north\" ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\t\tlat:_ChunkSizes = 510 ;\n",
      "\tshort ts(ts) ;\n",
      "\t\tts:_FillValue = -32767s ;\n",
      "\t\tts:_ChunkSizes = 3 ;\n",
      "\tshort time(time) ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:units = \"days since 1950-01-01 00:00:00\" ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:calendar = \"gregorian\" ;\n",
      "\t\ttime:_ChunkSizes = 1 ;\n",
      "\tshort time_vectors(time, ts) ;\n",
      "\t\ttime_vectors:_ChunkSizes = 1, 3 ;\n",
      "\tfloat tasmin(time, lat, lon) ;\n",
      "\t\ttasmin:long_name = \"air_temperature\" ;\n",
      "\t\ttasmin:standard_name = \"air_temperature\" ;\n",
      "\t\ttasmin:units = \"K\" ;\n",
      "\t\ttasmin:_FillValue = 9.96921e+36f ;\n",
      "\t\ttasmin:_ChunkSizes = 31, 102, 267 ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:Conventions = \"CF-1.5\" ;\n",
      "\t\t:title = \"NRCAN 10km Gridded Climate Dataset\" ;\n",
      "\t\t:history = \"2016-01-05T16:30:06: Convert from original format to NetCDF\" ;\n",
      "\t\t:institution = \"NRCAN\" ;\n",
      "\t\t:source = \"ANUSPLIN\" ;\n",
      "\t\t:redistribution = \"Redistribution policy unknown. For internal use only.\" ;\n",
      "\t\t:DODS_EXTRA.Unlimited_Dimension = \"time\" ;\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref = parseStatus(execute)\n",
    "print('Output reference :\\n*', ref)\n",
    "\n",
    "r = requests.get(ref, verify=verify_ssl)\n",
    "print('\\nNCDUMP results :\\n',r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdy",
   "language": "python",
   "name": "birdy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
